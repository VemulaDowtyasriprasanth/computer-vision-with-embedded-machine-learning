{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "solution-curation-and-raw-uploader.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC2XM9ueyLhu"
      },
      "source": [
        "# Solution: Curation and Raw Uploader\n",
        "\n",
        "[![Open In Colab <](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ShawnHymel/computer-vision-with-embedded-machine-learning/blob/master/1.3.5%20-%20Project%20-%20Curate%20Dataset%20and%20Train%20Model/solution_curation_and_raw_uploader.ipynb)\n",
        "\n",
        "Run this notebook to convert images to a single row of raw, normalized values (between 0 and 1) and upload them to Edge Impulse as raw samples. Note that pixel values will be normalized to be between 0 and 1.\n",
        "\n",
        "This notebook also demonstrates the optional code to select one class as the target class, keep the background class, and set everything else to \"other.\" Code changes from the original raw uploader script have been denoted by the following style of comment:\n",
        "\n",
        "```\n",
        "# ***Solution*** <rest of comment>\n",
        "```\n",
        "\n",
        "From this, you can find the changes that were made to this notebook by searching (e.g. ctrl+f) for \"***\".\n",
        "\n",
        "Create a folder named \"dataset\" in the /content directory and upload your images there. The images should be divided into their respective classes, where each class has its own folder with the name of the class. For example:\n",
        "\n",
        "<pre>\n",
        "/content\n",
        "    |- dataset\n",
        "        |- background\n",
        "        |- capacitor\n",
        "        |- diode\n",
        "        |- led\n",
        "        |- resistor\n",
        "</pre>\n",
        "\n",
        "Author: EdgeImpulse, Inc.<br>\n",
        "Date: July 30, 2021<br>\n",
        "License: [Apache-2.0](apache.org/licenses/LICENSE-2.0)<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhHG2__GyJjs"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random, os, PIL, json, time, hmac, hashlib, requests, threading, queue\n",
        "\n",
        "from skimage.transform import resize                      # Used to scale/resize image arrays"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu2l_Lm0yhtJ"
      },
      "source": [
        "### Settings\n",
        "\n",
        "# Edge Impulse > your_project > Dashboard > Keys\n",
        "EI_API_KEY = \"ei_afb282f2bdd2b8e36c78a2282d9907c47897b8e54443a5c446b64007eb6084c2\" \n",
        "EI_HMAC_KEY = \"8a6e0eab4d2306c732ad3be540ddad75\"\n",
        "\n",
        "# ***Solution*** Set our target classes\n",
        "TARGET_CLASS = \"resistor\"         # Must be a folder name present in the dataset\n",
        "BACKGROUND_CLASS = \"background\"   # Must be a folder name present in the dataset\n",
        "OTHER_CLASS = \"other\"             # Does not need to be a folder in the dataset\n",
        "\n",
        "# Number of threads to run to upload data to Edge Impulse\n",
        "NUM_THREADS = 20\n",
        "\n",
        "# Location of dataset\n",
        "DATASET_PATH = \"/content/dataset\"\n",
        "\n",
        "# Desired resolution of images\n",
        "TARGET_WIDTH = 28\n",
        "TARGET_HEIGHT = 28\n",
        "\n",
        "# Invert image (dark backgrounds can sometimes improve accuracy)\n",
        "INVERT = False\n",
        "\n",
        "# Set aside 20% for test set (Edge Impulse automatically extracts validation set during training)\n",
        "TEST_RATIO = 0.2\n",
        "\n",
        "# You are welcome to change the seed to try a different validation set split\n",
        "random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL3YlAXTrZS-"
      },
      "source": [
        "## Curate Image Dataset\n",
        "\n",
        "The following cells perform the following:\n",
        " * Load images from filesystem as grayscale values\n",
        " * Set aside some portion of the dataset as test data\n",
        " * Resize images\n",
        " * Normalize pixel value from [0, 255] to [0.0, 1.0]\n",
        " * Flatten images to 1D array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXcJLxcv0yOT"
      },
      "source": [
        "### Load images as Numpy arrays\n",
        "\n",
        "# We want to record the labels and assign a ground truth label as a number to each sample\n",
        "labels = []\n",
        "y_all = []    # Lowercase 'y' - 1D vector of the ground truth labels (n)\n",
        "X_all = []    # Uppercase 'X' - 3D array of all image samples (n x width x height)\n",
        "\n",
        "# Find the directories in the dataset folder (skip the Jupyter Notebook checkpoints hidden folder)\n",
        "for label in os.listdir(DATASET_PATH):\n",
        "  class_dir = os.path.join(DATASET_PATH, label)\n",
        "  if os.path.isdir(class_dir) and label != \".ipynb_checkpoints\":\n",
        "\n",
        "    # ***Solution*** Change label to \"other\" if not background or target class\n",
        "    if (label != TARGET_CLASS) and (label != BACKGROUND_CLASS):\n",
        "      label = OTHER_CLASS\n",
        "\n",
        "    # ***Solution*** Only append label to list of labels if not already in there\n",
        "    if label not in labels:\n",
        "      labels.append(label)\n",
        "\n",
        "    # Go through each image in the folder\n",
        "    for i, file in enumerate(os.listdir(class_dir)):\n",
        "\n",
        "      # Skip the Jupyter Notebook checkpoints folder that sometimes gets added\n",
        "      if file != \".ipynb_checkpoints\":\n",
        "\n",
        "        # Open image and convert to grayscale\n",
        "        file_path = os.path.join(class_dir, file)\n",
        "        img = PIL.Image.open(file_path).convert('L')\n",
        "\n",
        "        # Convert the image to a Numpy array, optionally invern, and append to X\n",
        "        img_array = np.asarray(img)\n",
        "        if INVERT:\n",
        "          img_array = 255 - img_array\n",
        "        X_all.append(img_array)\n",
        "\n",
        "        # Add label to the y array\n",
        "        y_all.append(label)\n",
        "\n",
        "    # Show how many images we loaded\n",
        "    print(\"Added\", str(i + 1), \"images from\", label)\n",
        "\n",
        "# Calculate total number of samples\n",
        "num_samples = len(X_all)\n",
        "\n",
        "# Sort the labels list by alphabetical order\n",
        "labels = sorted(labels)\n",
        "\n",
        "# Print out labels and number of samples\n",
        "print(labels)\n",
        "print(\"Number of samples:\", num_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJrS0Oz31NkI"
      },
      "source": [
        "### Shuffle samples and labels together, divide into test and training sets\n",
        "\n",
        "# Shuffle samples and associated labels together\n",
        "X_y = list(zip(X_all, y_all))\n",
        "random.shuffle(X_y)\n",
        "X_all, y_all = zip(*X_y)\n",
        "\n",
        "# Calculate number of validation and test samples to put aside (round down)\n",
        "num_samples_test = int(TEST_RATIO * num_samples)\n",
        "\n",
        "# The first `num_samples_test` samples of the shuffled list becomes the test set\n",
        "X_test = X_all[:num_samples_test]\n",
        "y_test = y_all[:num_samples_test]\n",
        "\n",
        "# The remaining samples become the training set\n",
        "X_train = X_all[num_samples_test:]\n",
        "y_train = y_all[num_samples_test:]\n",
        "\n",
        "# Remember the number of samples in the test set\n",
        "num_samples_train = len(X_train)\n",
        "\n",
        "# Print out the number of test and training samples\n",
        "print(\"Number of test samples:\", num_samples_test)\n",
        "print(\"Number of training samples:\", num_samples_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FwDtw_DazYG"
      },
      "source": [
        "### View one of the training samples\n",
        "\n",
        "# Chose which sample you want to view\n",
        "idx = 0\n",
        "\n",
        "# Print out label (numbe and string) and part of the array\n",
        "print(\"Label: \" + y_train[idx])\n",
        "print(X_train[idx])\n",
        "\n",
        "# Display image from array\n",
        "plt.imshow(X_train[idx], cmap='gray', vmin=0, vmax=255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eVgRZnHc6_y"
      },
      "source": [
        "### Function to resize list of images\n",
        "def resize_images(images, width, height, anti_aliasing=True):\n",
        "  \"\"\"\n",
        "  Prove a list of Numpy arrays (in images parameter) to have them all resized to desired height and\n",
        "  width. Returns the list of newly resized image arrays.\n",
        "\n",
        "  NOTE: skimage resize returns *normalized* image arrays (values between 0..1)\n",
        "  \"\"\"\n",
        "  X_out = []\n",
        "  for i, img in enumerate(images):\n",
        "    X_out.append(resize(img, (height, width), anti_aliasing=anti_aliasing))\n",
        "  return X_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNpuq5Lxa9Ck"
      },
      "source": [
        "### Scale/crop images (Note: also normalizes data to 0..1)\n",
        "\n",
        "# Resize (scale) all images in the training set\n",
        "X_train = resize_images(X_train, TARGET_WIDTH, TARGET_HEIGHT)\n",
        "\n",
        "# Resize (scale) all images in the test set\n",
        "X_test = resize_images(X_test, TARGET_WIDTH, TARGET_HEIGHT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL9W4Pw1cVon"
      },
      "source": [
        "### View training sample again (after they all have been scaled)\n",
        "\n",
        "# Chose which sample you want to view\n",
        "idx = 0\n",
        "\n",
        "# Print out label (numbe and string) and part of the array\n",
        "print(\"Label: \" + y_train[idx])\n",
        "print(\"First row:\", X_train[idx][:1,:])\n",
        "\n",
        "# Display image from array (note that images have been normalized)\n",
        "plt.imshow(X_train[idx], cmap='gray', vmin=0, vmax=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5atQn3JsHQo"
      },
      "source": [
        "### Convert list of samples into Numpy arrays\n",
        "\n",
        "# Convert sets\n",
        "X_train = np.asarray(X_train)\n",
        "X_test = np.asarray(X_test)\n",
        "\n",
        "# Print out the new Numpy array shapes (always a good idea to check the shapes!)\n",
        "print(\"Training X:\", X_train.shape)\n",
        "print(\"Test X:\", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0H4V7jGrQdk"
      },
      "source": [
        "### Flatten each image to a 1D vector (DNN requires 1D input)\n",
        "\n",
        "# Compute length of 1D array that we will flatten each image to\n",
        "len_vector = TARGET_WIDTH * TARGET_WIDTH\n",
        "\n",
        "# Flatten matricies to vectors\n",
        "X_train = X_train.reshape(num_samples_train, len_vector)\n",
        "X_test = X_test.reshape(num_samples_test, len_vector)\n",
        "\n",
        "# Print out the new Numpy array shapes (always a good idea to check the shapes!)\n",
        "print(\"Training X:\", X_train.shape)\n",
        "print(\"Test X:\", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JPj36oxn_cq"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "The following functions are used to assist in task of uploading samples to your Edge Impulse project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D32TWqoeJ3YI"
      },
      "source": [
        "def create_json_wrapper():\n",
        "  \"\"\"\n",
        "  Construct initial JSON wrapper as a template\n",
        "  \"\"\"\n",
        "\n",
        "  # Start with all zeros. Hs256 gives 32 bytes and we encode in hex. So, we need 64 characters here.\n",
        "  empty_signature = ''.join(['0'] * 64)\n",
        "\n",
        "  # Create JSON wrapper for data\n",
        "  data = {\n",
        "      \"protected\": {\n",
        "          \"ver\": \"v1\",\n",
        "          \"alg\": \"HS256\",\n",
        "          \"iat\": time.time()                  # Epoch time, seconds since 1970\n",
        "      },\n",
        "      \"signature\": empty_signature,\n",
        "      \"payload\": {\n",
        "          \"device_type\": \"pre-made\",          # Pre-made dataset (not collected)\n",
        "          \"interval_ms\": 1,                   # Pretend it's interval of 1 ms\n",
        "          \"sensors\": [\n",
        "              { \"name\": \"img\", \"units\": \"B\" } # Unitless (\"Byte\" data)\n",
        "          ],\n",
        "          \"values\": []\n",
        "      }\n",
        "  }\n",
        "\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af8z5kdQoEMX"
      },
      "source": [
        "def send_sample(data, label, test_set=False):\n",
        "  \"\"\"\n",
        "  Send raw data sample to Edge Impulse project, return HTTP status code\n",
        "  \"\"\"\n",
        "\n",
        "  # Encode message in JSON format\n",
        "  encoded = json.dumps(data)\n",
        "\n",
        "  # Sign message\n",
        "  signature = hmac.new(bytes(EI_HMAC_KEY, 'utf-8'), \n",
        "                      msg = encoded.encode('utf-8'), \n",
        "                      digestmod = hashlib.sha256).hexdigest()\n",
        "\n",
        "  # Set the signature in the message and encode data again to JSON format\n",
        "  data['signature'] = signature\n",
        "  encoded = json.dumps(data)\n",
        "\n",
        "  # Construct URL based on dataset being sent\n",
        "  if test_set:\n",
        "    url = 'https://ingestion.edgeimpulse.com/api/testing/data'\n",
        "  else:\n",
        "    url = 'https://ingestion.edgeimpulse.com/api/training/data'\n",
        "\n",
        "  # Upload the data to project\n",
        "  res = requests.post(url=url,\n",
        "                      data=encoded,\n",
        "                      headers={\n",
        "                          'Content-Type': 'application/json',\n",
        "                          'x-file-name': str(label),\n",
        "                          'x-api-key': EI_API_KEY\n",
        "                      })\n",
        "  \n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCnwArbaoIym"
      },
      "source": [
        "def upload_sample(len_vector, is_test_set):\n",
        "  \"\"\"\n",
        "  Pull sample and label from queue and send to Edge Impulse server. To be called within a thread.\n",
        "  \"\"\"\n",
        "\n",
        "  global q\n",
        "\n",
        "  while not q.empty():\n",
        "\n",
        "    # Start with empty JSON wrapper\n",
        "    data = create_json_wrapper()\n",
        "\n",
        "    # Fill up values field (we need to convert to float to avoid JSON error)\n",
        "    sample, label = q.get()\n",
        "    for j in range(len_vector):\n",
        "      data['payload']['values'].append(float(sample[j]))\n",
        "\n",
        "    # Send sample\n",
        "    res = send_sample(data, label, test_set=is_test_set)\n",
        "\n",
        "    # Check response code\n",
        "    if (res.status_code != 200):\n",
        "      print(\"Failed to upload file to Edge Impulse\", res.status_code, res.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPdjS2zYoQOB"
      },
      "source": [
        "## Upload training and test sets to Edge Impulse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ayuDYgvoMvd"
      },
      "source": [
        "### Use many threads to send training data and labels to Edge Impulse project\n",
        "\n",
        "# Fill queue with training data and labels\n",
        "q = queue.Queue()\n",
        "for i in range(num_samples_train):\n",
        "  q.put((X_train[i], y_train[i]))\n",
        "\n",
        "# Create and start threads\n",
        "threads = []\n",
        "for i in range(NUM_THREADS):\n",
        "  threads.append(threading.Thread(target=upload_sample, args=(len_vector, False)))\n",
        "  threads[i].start()\n",
        "\n",
        "# Wait for threads to be done\n",
        "for thread in threads:\n",
        "  thread.join()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsygGvJoTUo"
      },
      "source": [
        "### Use many threads to send test data and labels to Edge Impulse project\n",
        "\n",
        "# Fill queue with test data and labels\n",
        "q = queue.Queue()\n",
        "for i in range(num_samples_test):\n",
        "  q.put((X_test[i], y_test[i]))\n",
        "\n",
        "# Create and start threads\n",
        "threads = []\n",
        "for i in range(NUM_THREADS):\n",
        "  threads.append(threading.Thread(target=upload_sample, args=(len_vector, True)))\n",
        "  threads[i].start()\n",
        "\n",
        "# Wait for threads to be done\n",
        "for thread in threads:\n",
        "  thread.join()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
